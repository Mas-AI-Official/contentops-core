# Content Factory Environment Configuration
# Python 3.11 recommended for best compatibility

# ============================================
# Paths (optional - defaults work for most setups)
# ============================================
# BASE_PATH=D:/Ideas/content_factory
# DATA_PATH=D:/Ideas/content_factory/data
# MODELS_PATH=D:/Ideas/content_factory/models

# Model cache paths (set these to keep downloads in project folder)
# HF_HOME=D:/Ideas/content_factory/models/whisper/hf
# TORCH_HOME=D:/Ideas/content_factory/models/torch
# XDG_CACHE_HOME=D:/Ideas/content_factory/models/cache

# ============================================
# LLM Settings
# ============================================
# Provider options: ollama (local), mcp (external APIs), hf_router (intelligent routing)
LLM_PROVIDER=ollama

# Ollama (Local, Default)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b
OLLAMA_FAST_MODEL=llama3.2:3b

# Hugging Face Router (Intelligent Model Routing - RECOMMENDED for best quality)
# LLM_PROVIDER=hf_router
# HF_ROUTER_BASE_URL=https://router.huggingface.co/v1
# HF_TOKEN=your_huggingface_token_here  # Get from https://huggingface.co/settings/tokens
# HF_ROUTER_MODEL=  # Leave empty for auto-routing, or specify: meta-llama/Llama-3.3-70B-Instruct
# HF_ROUTER_REASONING_LEVEL=medium  # low, medium, high (reasoning effort)
# HF_ROUTER_TEMPERATURE=0.7  # 0.0-2.0 (lower = more deterministic, higher = more creative)
# HF_ROUTER_MAX_TOKENS=2048
# HF_ROUTER_TIMEOUT=120.0  # seconds

# ============================================
# TTS Settings
# ============================================
TTS_PROVIDER=xtts
XTTS_ENABLED=true
XTTS_SERVER_URL=http://localhost:8020
# XTTS_SPEAKER_WAV=path/to/speaker.wav
XTTS_LANGUAGE=en

# ElevenLabs (optional fallback)
# ELEVENLABS_API_KEY=your_api_key_here
# ELEVENLABS_VOICE_ID=21m00Tcm4TlvDq8ikWAM
# ELEVENLABS_MODEL=eleven_monolingual_v1

# ============================================
# Whisper Settings (subtitles)
# ============================================
WHISPER_MODEL=base
WHISPER_DEVICE=cuda
WHISPER_COMPUTE_TYPE=float16

# ============================================
# FFmpeg Settings
# ============================================
FFMPEG_PATH=ffmpeg
FFPROBE_PATH=ffprobe

# ============================================
# YouTube API
# Follow: https://developers.google.com/youtube/v3/getting-started
# ============================================
# YOUTUBE_CLIENT_ID=your_client_id
# YOUTUBE_CLIENT_SECRET=your_client_secret
# YOUTUBE_REFRESH_TOKEN=your_refresh_token

# ============================================
# Instagram Graph API
# Follow: https://developers.facebook.com/docs/instagram-api/getting-started
# ============================================
# INSTAGRAM_ACCESS_TOKEN=your_access_token
# INSTAGRAM_BUSINESS_ACCOUNT_ID=your_account_id

# ============================================
# TikTok Content Posting API
# Follow: https://developers.tiktok.com/doc/content-posting-api-get-started
# NOTE: Unverified apps can only post as PRIVATE until audit approval
# ============================================
# TIKTOK_CLIENT_KEY=your_client_key
# TIKTOK_CLIENT_SECRET=your_client_secret
# TIKTOK_ACCESS_TOKEN=your_access_token
# TIKTOK_OPEN_ID=your_open_id
# TIKTOK_VERIFIED=false

# ============================================
# Worker Settings
# ============================================
WORKER_ENABLED=true
WORKER_INTERVAL_SECONDS=60
MAX_CONCURRENT_JOBS=2

# ============================================
# MCP / External Connectors (optional)
# ============================================
# MCP_ENABLED=false
# MCP_DEFAULT_TIMEOUT=60
# Example:
# MCP_CONNECTORS_JSON=[{"name":"openai","type":"llm","base_url":"https://api.openai.com/v1","auth_header":"Authorization","auth_env":"OPENAI_API_KEY","auth_prefix":"Bearer "}]
# MCP_LLM_CONNECTOR=openai
# MCP_LLM_PATH=v1/chat/completions
# MCP_LLM_MODEL=gpt-4o-mini

# ============================================
# Video Defaults
# ============================================
DEFAULT_VIDEO_WIDTH=1080
DEFAULT_VIDEO_HEIGHT=1920
DEFAULT_VIDEO_FPS=30
DEFAULT_BG_MUSIC_VOLUME=0.1

# Video Generator Provider (optional)
# VIDEO_GEN_PROVIDER=ffmpeg
# LTX_API_URL=http://127.0.0.1:8188  # ComfyUI API (fallback)
# LTX_MODEL_PATH=D:/Ideas/content_factory/models/ltx  # Direct Python API (preferred)
# LTX_USE_FP8=true  # Use FP8 quantization for 8GB VRAM
